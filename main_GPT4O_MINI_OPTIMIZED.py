#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üöÄ –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –°–¢–†–ê–¢–ï–ì–ò–Ø - GPT-4o-mini –¥–ª—è J ‚â• 0.70

–†–ï–ê–õ–ò–ó–û–í–ê–ù–ù–´–ï –§–ê–ó–´:
‚úÖ –§–∞–∑–∞ 1: –£—Å–∏–ª–µ–Ω–Ω—ã–π Chain-of-Thought –¥–ª—è GPT-4o-mini
‚úÖ –§–∞–∑–∞ 2: –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ + –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ª–µ–∫—Å–∏–∫–æ–Ω
‚úÖ –§–∞–∑–∞ 3: Multi-candidate generation (3 –∫–∞–Ω–¥–∏–¥–∞—Ç–∞)
‚úÖ –§–∞–∑–∞ 4: –≠–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–æ–µ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ (–ë–ï–ó LaBSE –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏)
‚úÖ –§–∞–∑–∞ 5: –î–≤—É—Ö–ø—Ä–æ—Ö–æ–¥–Ω–∞—è –¥–µ—Ç–æ–∫—Å–∏—Ñ–∏–∫–∞—Ü–∏—è

–¶–ï–õ–ï–í–û–ô J-SCORE: 0.70-0.75
–ú–û–î–ï–õ–¨: GPT-4o-mini
API: https://api.artemox.com/v1
"""

import re
import os
import pandas as pd
from openai import OpenAI
from tqdm import tqdm
import time
from typing import List, Tuple

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –ù–ê–°–¢–†–û–ô–ö–ê API GPT-4o-mini
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

API_KEY = "sk-C4Ju9Yy2-EKOf6SHs-jBPA"
BASE_URL = "https://api.artemox.com/v1"
MODEL_NAME = "gpt-4o-mini"

client = OpenAI(
    api_key=API_KEY,
    base_url=BASE_URL
)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
INPUT_FILE = "dev_inputs.tsv"
OUTPUT_FILE = "submission_gpt4o_mini.tsv"
NUM_CANDIDATES = 3  # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º 3 –∫–∞–Ω–¥–∏–¥–∞—Ç–∞

# –°—á–µ—Ç—á–∏–∫–∏
total_api_calls = 0
total_input_tokens = 0
total_output_tokens = 0

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –§–ê–ó–ê 2: –†–ê–°–®–ò–†–ï–ù–ù–´–ô –¢–ê–¢–ê–†–°–ö–ò–ô –¢–û–ö–°–ò–ß–ù–´–ô –õ–ï–ö–°–ò–ö–û–ù
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

TATAR_TOXIC_LEXICON = {
    # === –†–£–°–°–ö–ò–ï –ú–ê–¢–´ (–≤—ã—Å—à–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç) ===
    'explicit_russian': [
        '–±–ª—è', '–±–ª—è—Ç', '–±–ª—ç—Ç', '–±–ª—è—Ç—å',
        '—Ö—É–π', '—Ö—É—è', '—Ö—É—é', '—Ö—É–µ–º', '—Ö—É–ª–∏', '—Ö—É–π–Ω—è',
        '–ø–∏–∑–¥', '–ø–∏–∑–¥–µ', '–ø–∏–∑–¥–µ—Ü', '–ø–∏–∑–¥—É',
        '–µ–±–∞–Ω', '–µ–±–∞—Ç—å', '–µ–±–∞–ª', '–µ–±–ª–æ', '–µ–±–∞—à',
        '—Å—É–∫–∞', '—Å—É–∫–∏', '—Å—É–∫',
        '–ø–∏–¥–æ—Ä', '–ø–∏–¥–∞—Ä', '–ø–∏–¥—Ä',
    ],

    # === –†–£–°–°–ö–ò–ï –í–£–õ–¨–ì–ê–†–ò–ó–ú–´ (—Å—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç) ===
    'vulgar_russian': [
        '–∂–æ–ø', '–∂–æ–ø–∞', '–∂–æ–ø–µ', '–∂–æ–ø—É', '–∂–æ–ø–æ–π',
        '—Å—Ä–∞—Ç—å', '—Å—Ä–∞–∫–∞', '—Å—Ä–∞–∫—É',
        '–≥–∞–≤–Ω–æ', '–≥–æ–≤–Ω–æ', '–≥–æ–≤–Ω–∞',
        '–¥–µ—Ä—å–º–æ', '–¥–µ—Ä—å–º–∞',
    ],

    # === –°–õ–ê–ë–´–ï –†–£–°–°–ö–ò–ï (–Ω–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç) ===
    'weak_russian': [
        '–±–ª–∏–Ω', '–±–ª–∏–Ω—Å–∫–∏–π',
        '—Ö—Ä–µ–Ω', '—Ö—Ä–µ–Ω–∞', '—Ö—Ä–µ–Ω–æ–≤',
        '—á–µ—Ä—Ç', '—á–µ—Ä—Ç–∞', '—á–µ—Ä—Ç–æ–≤',
        '—Ñ–∏–≥', '—Ñ–∏–≥–∞',
    ],

    # === –¢–ê–¢–ê–†–°–ö–ò–ï –û–°–ö–û–†–ë–õ–ï–ù–ò–Ø (–≤—ã—Å—à–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç) ===
    'explicit_tatar': [
        '–∫—É—Ç–∞–∫', '–∫—É—Ç–∞–∫–±–∞—à', '–∫—É—Ç–∞–∫–ª–∞—Ä',
        '—Ç–∏–ª–µ', '—Ç–∏–ª–µ–¥–µ—Ä',
        '–¥—É–Ω–≥—ã–∑', '—á—É—á–∫–∞',  # —Å–≤–∏–Ω—å—è
        '—Ç–∏–Ω—Ç”ô–∫', '—Ç–∏–Ω—Ç–µ–∫–ª”ô—Ä',
        '–∞–Ω–≥—ã—Ä–∞', '–∞–Ω–≥—ã—Ä–∞–ª—ã',
        '—É–±—ã—Ä–ª—ã', '—É–±—ã—Ä–ª—ã–∫',
    ],

    # === –¢–ê–¢–ê–†–°–ö–ò–ï –í–£–õ–¨–ì–ê–†–ò–ó–ú–´ ===
    'vulgar_tatar': [
        '—Å–æ—Å–æ–ø', '—Å–æ—Å—É',
        '—Ç—ã—á–∫–∞–∫', '—Ç—ã—á–∫–∞–∫–ª–∞—Ä',
        '–º–∞—Ä–∂–∞',
        '–±—ç—Ç—ç–∫', '—Ç–∏—à–µ–∫',
    ],

    # === CODE-SWITCHING –ö–û–ù–°–¢–†–£–ö–¶–ò–ò ===
    'code_switching': [
        '–Ω–∞ —Ö—É–π', '–Ω–∞—Ö—É–π', '–Ω–∞ —Ö–µ—Ä',
        '–ø–æ—à–æ–ª', '–∏–¥–∏ –Ω–∞',
        '—á—Ç–æ –ª–∏', '—à—Ç–æ –ª–∏',
        '–¥–æ —Ö—É—è', '–¥–æ—Ö—É—è',
    ],
}

def get_all_toxic_words() -> set:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–ª–æ—Å–∫–∏–π set –≤—Å–µ—Ö —Ç–æ–∫—Å–∏—á–Ω—ã—Ö —Å–ª–æ–≤"""
    all_words = []
    for category in TATAR_TOXIC_LEXICON.values():
        all_words.extend(category)
    return set(all_words)

TOXIC_WORDS_SET = get_all_toxic_words()

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –§–ê–ó–ê 2: –ê–î–ê–ü–¢–ò–í–ù–ê–Ø –¢–ï–ú–ü–ï–†–ê–¢–£–†–ê (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è mini)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def get_adaptive_temperature(text: str) -> float:
    """
    –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è GPT-4o-mini
    Mini –±–æ–ª–µ–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–∞ –∫ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–µ!

    Args:
        text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç

    Returns:
        –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ [0.1-0.35]
    """
    text_lower = text.lower()

    # –ü–æ–¥—Å—á—ë—Ç —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    strong_count = 0
    weak_count = 0

    for word in TATAR_TOXIC_LEXICON['explicit_russian'] + TATAR_TOXIC_LEXICON['explicit_tatar']:
        if word in text_lower:
            strong_count += 1

    for word in TATAR_TOXIC_LEXICON['weak_russian']:
        if word in text_lower:
            weak_count += 1

    # –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞
    is_short = len(text.split()) < 8

    # –õ–æ–≥–∏–∫–∞ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã
    if strong_count >= 3:
        return 0.1  # –û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è ‚Äî –º–Ω–æ–≥–æ —è–≤–Ω–æ–π —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏
    elif strong_count >= 1 and is_short:
        return 0.15  # –ù–∏–∑–∫–∞—è ‚Äî –∫–æ—Ä–æ—Ç–∫–∏–π —Ç–æ–∫—Å–∏—á–Ω—ã–π —Ç–µ–∫—Å—Ç
    elif strong_count >= 1:
        return 0.2  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –¥–ª—è —Ç–æ–∫—Å–∏—á–Ω—ã—Ö
    elif weak_count > 0:
        return 0.3  # –°—Ä–µ–¥–Ω—è—è ‚Äî —Å–ª–∞–±–∞—è —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç—å
    elif is_short:
        return 0.25  # –ö–æ—Ä–æ—Ç–∫–∏–π –Ω–µ—Ç–æ–∫—Å–∏—á–Ω—ã–π
    else:
        return 0.35  # –í—ã—à–µ ‚Äî –≤–æ–∑–º–æ–∂–Ω–∞ –Ω–µ—è–≤–Ω–∞—è —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç—å

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –§–ê–ó–ê 1: –£–°–ò–õ–ï–ù–ù–´–ô CHAIN-OF-THOUGHT –ü–†–û–ú–ü–¢
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def create_enhanced_cot_prompt(text: str) -> str:
    """
    –ü—Ä–æ–º–ø—Ç —Å —É—Å–∏–ª–µ–Ω–Ω—ã–º CoT –¥–ª—è GPT-4o-mini
    –ë–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏ –ø—Ä–∏–º–µ—Ä—ã
    """

    prompt = f"""–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –¥–µ—Ç–æ–∫—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–∞—Ç–∞—Ä—Å–∫–æ–≥–æ —è–∑—ã–∫–∞. –†–∞–±–æ—Ç–∞–π –ü–û–®–ê–ì–û–í–û.

üéØ –Ø–ó–´–ö: –¢–∞—Ç–∞—Ä—Å–∫–∏–π (—Ç—é—Ä–∫—Å–∫–∞—è —Å–µ–º—å—è, –∫–∏—Ä–∏–ª–ª–∏—Ü–∞/–ª–∞—Ç–∏–Ω–∏—Ü–∞)

‚ö†Ô∏è –û–°–û–ë–ï–ù–ù–û–°–¢–ò –¢–ê–¢–ê–†–°–ö–û–ì–û:
1. Code-switching —Å —Ä—É—Å—Å–∫–∏–º (–Ω–æ—Ä–º–∞–ª—å–Ω–æ –¥–ª—è –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤)
2. 80% –º–∞—Ç–æ–≤ ‚Äî —Ä—É—Å—Å–∫–∏–µ –∑–∞–∏–º—Å—Ç–≤–æ–≤–∞–Ω–∏—è (–∂–æ–ø–∞, –±–ª–∏–Ω, —Ö—Ä–µ–Ω, —á—É—á–∫–∞, –±–ª—è)
3. –¢–∞—Ç–∞—Ä—Å–∫–∏–µ –æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏—è: –∫—É—Ç–∞–∫, —Ç–∏–ª–µ, –¥—É–Ω–≥—ã–∑, —Ç–∏–Ω—Ç”ô–∫
4. –ê–≥–≥–ª—é—Ç–∏–Ω–∞—Ü–∏—è: –æ–¥–∏–Ω –∫–æ—Ä–µ–Ω—å ‚Üí –º–Ω–æ–≥–æ —Ñ–æ—Ä–º

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üìã –ü–û–®–ê–ì–û–í–´–ô –ê–õ–ì–û–†–ò–¢–ú:

–®–ê–ì 1: –ò–î–ï–ù–¢–ò–§–ò–ö–ê–¶–ò–Ø –¢–û–ö–°–ò–ß–ù–û–°–¢–ò
–ù–∞–π–¥–∏ –í–°–ï —Ç–æ–∫—Å–∏—á–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã:
- –†—É—Å—Å–∫–∏–µ –º–∞—Ç—ã (–±–ª—è, —Ö—É–π, –ø–∏–∑–¥, –µ–±–∞–Ω, —Å—É–∫–∞, –∂–æ–ø–∞, —Ö—Ä–µ–Ω, –±–ª–∏–Ω)
- –¢–∞—Ç–∞—Ä—Å–∫–∏–µ –æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏—è (–∫—É—Ç–∞–∫, —Ç–∏–ª–µ, –¥—É–Ω–≥—ã–∑, —Ç–∏–Ω—Ç”ô–∫, –∞–Ω–≥—ã—Ä–∞)
- –í—É–ª—å–≥–∞—Ä–Ω–∞—è –ª–µ–∫—Å–∏–∫–∞ (—Å–æ—Å–æ–ø, —Ç—ã—á–∫–∞–∫)
- @—É–ø–æ–º–∏–Ω–∞–Ω–∏—è (—á–∞—Å—Ç–æ —Ç–æ–∫—Å–∏—á–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç)

–®–ê–ì 2: –ê–ù–ê–õ–ò–ó –°–ú–´–°–õ–ê
–û–ø—Ä–µ–¥–µ–ª–∏ –æ—Å–Ω–æ–≤–Ω–æ–π —Å–º—ã—Å–ª –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ë–ï–ó —Ç–æ–∫—Å–∏—á–Ω—ã—Ö —Å–ª–æ–≤.
–ß—Ç–æ –∞–≤—Ç–æ—Ä —Ö–æ—Ç–µ–ª —Å–∫–∞–∑–∞—Ç—å? –ö–∞–∫–∞—è —ç–º–æ—Ü–∏—è (–≥–Ω–µ–≤/—é–º–æ—Ä/–∫—Ä–∏—Ç–∏–∫–∞)?

–®–ê–ì 3: –î–ï–¢–û–ö–°–ò–§–ò–ö–ê–¶–ò–Ø
–î–ª—è –ö–ê–ñ–î–û–ì–û —Ç–æ–∫—Å–∏—á–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ —Ä–µ—à–∏:
A) –£–¥–∞–ª–∏—Ç—å (–µ—Å–ª–∏ –º–æ–∂–Ω–æ –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ —Å–º—ã—Å–ª–∞)
B) –ó–∞–º–µ–Ω–∏—Ç—å –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–º —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–æ–º
C) –ü–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞—Ç—å (–µ—Å–ª–∏ –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è —Å–º—ã—Å–ª–∞)

–®–ê–ì 4: –ü–†–û–í–ï–†–ö–ê –ö–ê–ß–ï–°–¢–í–ê
‚úì –ù–µ—Ç —Ç–æ–∫—Å–∏—á–Ω—ã—Ö —Å–ª–æ–≤?
‚úì –°–º—ã—Å–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω?
‚úì –ó–≤—É—á–∏—Ç –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ?
‚úì –ü—É–Ω–∫—Ç—É–∞—Ü–∏—è/—ç–º–æ–¥–∑–∏ –Ω–∞ –º–µ—Å—Ç–µ?

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üìö –û–ë–£–ß–ê–Æ–©–ò–ï –ü–†–ò–ú–ï–†–´:

–ü—Ä–∏–º–µ—Ä 1 (–£–¥–∞–ª–µ–Ω–∏–µ —Ä—É—Å—Å–∫–æ–≥–æ –º–∞—Ç–∞):
–¢–æ–∫—Å–∏—á–Ω—ã–π: "—Å–∏–Ω–µ –∞–Ω–¥–∞ –±–∞—Ä—ã–±–µ—Ä –∫–æ—Ç–µ–ø —è—Ç–º—ã–π–ª–∞—Ä, —Ç–∞–∫ —á—Ç–æ, —Å–∏–¥–∏ —Ä–æ–≤–Ω–æ –Ω–∞ –∂–æ–ø–µ"
–®–ê–ì 1: –¢–æ–∫—Å–∏—á–Ω–æ—Å—Ç—å ‚Üí "–Ω–∞ –∂–æ–ø–µ" (—Ä—É—Å—Å–∫–∏–π –≤—É–ª—å–≥–∞—Ä–∏–∑–º)
–®–ê–ì 2: –°–º—ã—Å–ª ‚Üí "—Å–∏–¥–∏ —Å–ø–æ–∫–æ–π–Ω–æ/—Ç–∏—Ö–æ"
–®–ê–ì 3: –£–¥–∞–ª–∏—Ç—å "–Ω–∞ –∂–æ–ø–µ"
–î–µ—Ç–æ–∫—Å: "—Å–∏–Ω–µ –∞–Ω–¥–∞ –±–∞—Ä—ã–±–µ—Ä –∫–æ—Ç–µ–ø —è—Ç–º—ã–π–ª–∞—Ä, —Ç–∞–∫ —á—Ç–æ, —Å–∏–¥–∏ —Ä–æ–≤–Ω–æ"

–ü—Ä–∏–º–µ—Ä 2 (–¢–∞—Ç–∞—Ä—Å–∫–æ–µ –æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏–µ):
–¢–æ–∫—Å–∏—á–Ω—ã–π: "–ö—É–ø–º–µ –∞—à–∞—Ä–≥–∞ –±—É–ª–∞ –∏–Ω–¥–µ? –°–∏–º–µ—Ä–µ–ø —á—É—á–∫–∞ –±—É–ª–∞—Å—ã–∑ –±–∏—Ç"
–®–ê–ì 1: –¢–æ–∫—Å–∏—á–Ω–æ—Å—Ç—å ‚Üí "—á—É—á–∫–∞" (—Å–≤–∏–Ω—å—è = –æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏–µ)
–®–ê–ì 2: –°–º—ã—Å–ª ‚Üí –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ –ø–µ—Ä–µ–µ–¥–∞–Ω–∏–∏
–®–ê–ì 3: –£–¥–∞–ª–∏—Ç—å "—á—É—á–∫–∞"
–î–µ—Ç–æ–∫—Å: "–ö—É–ø–º–µ –∞—à–∞—Ä–≥–∞ –±—É–ª–∞ –∏–Ω–¥–µ? –°–∏–º–µ—Ä–µ–ø –±—É–ª–∞—Å—ã–∑ –±–∏—Ç"

–ü—Ä–∏–º–µ—Ä 3 (–ö–æ–º–±–æ: @user + –æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏–µ):
–¢–æ–∫—Å–∏—á–Ω—ã–π: "@user, —Å–∏–Ω –∫–∏–ª –¥–∞–≤–∞–π, –∫—É—Ç–∞–∫ —Å—ã—Ä–ª–∞–º–∞!"
–®–ê–ì 1: –¢–æ–∫—Å–∏—á–Ω–æ—Å—Ç—å ‚Üí @user (–∫–æ–Ω—Ç–µ–∫—Å—Ç), "–∫—É—Ç–∞–∫" (–∑–∞–¥–Ω–∏—Ü–∞)
–®–ê–ì 2: –°–º—ã—Å–ª ‚Üí –ø—Ä–∏–∑—ã–≤ –ø—Ä–∏–π—Ç–∏, –Ω–µ –∂–∞–ª–æ–≤–∞—Ç—å—Å—è
–®–ê–ì 3: –£–¥–∞–ª–∏—Ç—å –æ–±–∞
–î–µ—Ç–æ–∫—Å: "—Å–∏–Ω –∫–∏–ª –¥–∞–≤–∞–π, —Å—ã—Ä–ª–∞–º–∞!"

–ü—Ä–∏–º–µ—Ä 4 (–°–ª–∞–±—ã–π –≤—É–ª—å–≥–∞—Ä–∏–∑–º + —ç–º–æ—Ü–∏—è):
–¢–æ–∫—Å–∏—á–Ω—ã–π: "–∞–ª–¥—ã–π–º –∏–Ω–¥–µ –º–∏–Ω!)) –º–∏–Ω–µ–∫–µ –±–ª–∏–Ω –π–æ—Ä—Ç—Ç–∞–Ω –¥–∞ —á—ã–∫–º—ã–π, –æ–π–¥—ç –≥—ç–Ω—ç —Å–æ—Å–æ–ø —è—Ç–∞ =D"
–®–ê–ì 1: –¢–æ–∫—Å–∏—á–Ω–æ—Å—Ç—å ‚Üí "–±–ª–∏–Ω" (—Å–ª–∞–±—ã–π), "—Å–æ—Å–æ–ø" (–≤—É–ª—å–≥–∞—Ä–Ω—ã–π)
–®–ê–ì 2: –°–º—ã—Å–ª ‚Üí —Ä–∞–∑–¥—Ä–∞–∂–µ–Ω–∏–µ + —é–º–æ—Ä (—Å–º–∞–π–ª–∏–∫ –≤–∞–∂–µ–Ω!)
–®–ê–ì 3: –£–¥–∞–ª–∏—Ç—å "–±–ª–∏–Ω", –∑–∞–º–µ–Ω–∏—Ç—å "—Å–æ—Å–æ–ø" ‚Üí –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–µ
–î–µ—Ç–æ–∫—Å: "–∞–ª–¥—ã–π–º –∏–Ω–¥–µ –º–∏–Ω!)) –º–∏–Ω–µ–∫–µ –π–æ—Ä—Ç—Ç–∞–Ω –¥–∞ —á—ã–∫–º—ã–π, –æ–π–¥—ç –≥—ç–Ω—ç —è—Ç–∞ =D"

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

‚úÖ –¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –í–´–í–û–î–£:
- –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –¥–µ—Ç–æ–∫—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
- –ë–ï–ó –æ–±—ä—è—Å–Ω–µ–Ω–∏–π —à–∞–≥–æ–≤ (—Ç–æ–ª—å–∫–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç)
- –°–æ—Ö—Ä–∞–Ω–∏ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—é (–∫–∏—Ä–∏–ª–ª–∏—Ü–∞/–ª–∞—Ç–∏–Ω–∏—Ü–∞ –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ)
- –°–æ—Ö—Ä–∞–Ω–∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é, —ç–º–æ–¥–∑–∏, —Å–º–∞–π–ª–∏–∫–∏
- –ù–ï –¥–æ–±–∞–≤–ª—è–π –Ω–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

–î–ï–¢–û–ö–°–ò–§–ò–¶–ò–†–£–ô –≠–¢–û–¢ –¢–ï–ö–°–¢:
{text}

–í–ê–ñ–ù–û: –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –¥–µ—Ç–æ–∫—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç, –ë–ï–ó –ø–æ—è—Å–Ω–µ–Ω–∏–π —à–∞–≥–æ–≤!"""

    return prompt

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –£–¢–ò–õ–ò–¢–´
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def clean_output(text: str) -> str:
    """–û—á–∏—â–∞–µ—Ç –≤—ã–≤–æ–¥ –º–æ–¥–µ–ª–∏ –æ—Ç –ª–∏—à–Ω–∏—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤"""
    if not text:
        return ""

    # –£–¥–∞–ª—è–µ–º –∫–∞–≤—ã—á–∫–∏ –≤–æ–∫—Ä—É–≥
    text = text.strip('"\'`')

    # –£–¥–∞–ª—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å—ã —Ç–∏–ø–∞ "–î–µ—Ç–æ–∫—Å:", "–†–µ–∑—É–ª—å—Ç–∞—Ç:" –∏ —Ç.–¥.
    prefixes = [
        '–¥–µ—Ç–æ–∫—Å:', '–¥–µ—Ç–æ–∫—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:',
        '—Ä–µ–∑—É–ª—å—Ç–∞—Ç:', '–æ—Ç–≤–µ—Ç:', 'output:',
    ]
    text_lower = text.lower()
    for prefix in prefixes:
        if text_lower.startswith(prefix):
            text = text[len(prefix):].strip()
            break

    return text.strip()

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –§–ê–ó–ê 3: MULTI-CANDIDATE GENERATION
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def generate_diverse_candidates(text: str, n: int = 3) -> List[str]:
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è N —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è GPT-4o-mini
    –°—Ç—Ä–∞—Ç–µ–≥–∏—è: –≤–∞—Ä—å–∏—Ä—É–µ–º temperature + seed

    Args:
        text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
        n: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤

    Returns:
        –°–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
    """
    global total_api_calls, total_input_tokens, total_output_tokens

    candidates = []
    base_prompt = create_enhanced_cot_prompt(text)

    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä –¥–ª—è –º–∏–Ω–∏-–º–æ–¥–µ–ª–∏
    base_temp = get_adaptive_temperature(text)
    temperatures = [base_temp, base_temp + 0.1, base_temp + 0.2]

    for i in range(min(n, len(temperatures))):
        temp = min(temperatures[i], 0.5)  # Cap at 0.5
        seed = 42 + (i * 17)  # –†–∞–∑–Ω—ã–µ seed'—ã

        try:
            resp = client.chat.completions.create(
                model=MODEL_NAME,
                messages=[{"role": "user", "content": base_prompt}],
                temperature=temp,
                max_tokens=400,
                top_p=0.95,
                seed=seed
            )

            total_api_calls += 1

            # –ü–æ–¥—Å—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤
            if hasattr(resp, 'usage') and resp.usage:
                total_input_tokens += resp.usage.prompt_tokens
                total_output_tokens += resp.usage.completion_tokens

            candidate = resp.choices[0].message.content.strip()
            candidate = clean_output(candidate)

            # –í–∞–ª–∏–¥–∞—Ü–∏—è: –Ω–µ –ø—É—Å—Ç–æ–π –∏ –Ω–µ —Å–ª–∏—à–∫–æ–º –∏–∑–º–µ–Ω—ë–Ω–Ω—ã–π
            if candidate and len(candidate) >= len(text) * 0.3:
                candidates.append(candidate)

        except Exception as e:
            print(f"‚ö†Ô∏è Candidate {i+1} generation failed: {e}")
            # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ
            time.sleep(1)
            continue

    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤, –≤–µ—Ä–Ω—É—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª
    if not candidates:
        candidates = [text]

    return candidates

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –§–ê–ó–ê 4: –≠–í–†–ò–°–¢–ò–ß–ï–°–ö–û–ï –†–ê–ù–ñ–ò–†–û–í–ê–ù–ò–ï (–ë–ï–ó LaBSE)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def rank_candidates_heuristic(candidates: List[str], original: str) -> str:
    """
    –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ë–ï–ó —Ç—è–∂—ë–ª—ã—Ö –º–æ–¥–µ–ª–µ–π (LaBSE)
    –¢–æ–ª—å–∫–æ –±—ã—Å—Ç—Ä—ã–µ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏ –¥–ª—è —Ö–∞–∫–∞—Ç–æ–Ω–∞

    Args:
        candidates: –°–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
        original: –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç

    Returns:
        –õ—É—á—à–∏–π –∫–∞–Ω–¥–∏–¥–∞—Ç
    """
    if len(candidates) == 1:
        return candidates[0]

    scores = []
    for candidate in candidates:
        score = 0.0
        cand_lower = candidate.lower()
        orig_lower = original.lower()

        # === 1. –î–ï–¢–û–ö–°–ò–§–ò–ö–ê–¶–ò–Ø (40% –≤–µ—Å–∞) ===
        # –°–∫–æ–ª—å–∫–æ —Ç–æ–∫—Å–∏—á–Ω—ã—Ö —Å–ª–æ–≤ –æ—Å—Ç–∞–ª–æ—Å—å?
        toxic_remaining = sum(1 for word in TOXIC_WORDS_SET if word in cand_lower)
        detox_score = 1.0 / (1.0 + toxic_remaining)
        score += detox_score * 0.4

        # === 2. SIMILARITY (35% –≤–µ—Å–∞) ===
        # –ü—Ä–æ—Å—Ç–∞—è Jaccard similarity –ø–æ —Å–ª–æ–≤–∞–º
        orig_words = set(orig_lower.split())
        cand_words = set(cand_lower.split())

        if orig_words:
            jaccard = len(orig_words & cand_words) / len(orig_words | cand_words)
        else:
            jaccard = 1.0

        # –î–ª–∏–Ω–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø–æ—Ö–æ–∂–∞
        length_ratio = min(len(candidate), len(original)) / max(len(candidate), len(original), 1)

        similarity = (jaccard * 0.6 + length_ratio * 0.4)
        score += similarity * 0.35

        # === 3. FLUENCY (25% –≤–µ—Å–∞) ===
        fluency = 1.0

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ–±—Ä—É–±–∫–∏
        words = candidate.strip().split()
        if words:
            last_word = words[-1].lower()
            # –ó–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ –ø—Ä–µ–¥–ª–æ–≥/—Å–æ—é–∑/—á–∞—Å—Ç–∏—Ü—É?
            if last_word in ['–Ω–∞', '–≤', '—Å', '–∫', '–ø–æ', '–∑–∞', '–∏', '–∞', '–Ω–æ', '–¥–∞', '–ª–∏']:
                fluency *= 0.5

        # –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π?
        if len(words) < 3:
            fluency *= 0.7

        # –ü—É—Å—Ç–æ–π –∏–ª–∏ —Ç–æ–ª—å–∫–æ –ø—Ä–æ–±–µ–ª—ã?
        if not candidate.strip():
            fluency = 0.0

        score += fluency * 0.25

        scores.append(score)

    # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–π
    if scores:
        best_idx = scores.index(max(scores))
        return candidates[best_idx]
    else:
        return candidates[0] if candidates else original

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –§–ê–ó–ê 5: –î–í–£–•–ü–†–û–•–û–î–ù–ê–Ø –î–ï–¢–û–ö–°–ò–§–ò–ö–ê–¶–ò–Ø
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def check_remaining_toxicity(text: str) -> List[str]:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –æ—Å—Ç–∞–ª–∏—Å—å –ª–∏ —Ç–æ–∫—Å–∏—á–Ω—ã–µ —Å–ª–æ–≤–∞ –≤ —Ç–µ–∫—Å—Ç–µ

    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏

    Returns:
        –°–ø–∏—Å–æ–∫ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è —Ç–æ–∫—Å–∏—á–Ω—ã—Ö —Å–ª–æ–≤
    """
    text_lower = text.lower()
    remaining = [word for word in TOXIC_WORDS_SET if word in text_lower]
    return remaining

def two_pass_detoxification(text: str) -> str:
    """
    –î–≤—É—Ö–ø—Ä–æ—Ö–æ–¥–Ω–∞—è –¥–µ—Ç–æ–∫—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –æ—Å—Ç–∞—Ç–æ—á–Ω–æ–π —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏
    –û—Å–æ–±–µ–Ω–Ω–æ –≤–∞–∂–Ω–æ –¥–ª—è GPT-4o-mini (–º–æ–∂–µ—Ç –ø—Ä–æ–ø—É—Å–∫–∞—Ç—å)

    Args:
        text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç

    Returns:
        –î–µ—Ç–æ–∫—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    """
    global total_api_calls, total_input_tokens, total_output_tokens

    # === PASS 1: –û—Å–Ω–æ–≤–Ω–∞—è –¥–µ—Ç–æ–∫—Å–∏—Ñ–∏–∫–∞—Ü–∏—è ===
    candidates_pass1 = generate_diverse_candidates(text, n=NUM_CANDIDATES)
    detoxed_pass1 = rank_candidates_heuristic(candidates_pass1, text)

    # === –ü–†–û–í–ï–†–ö–ê: –û—Å—Ç–∞–ª–∏—Å—å –ª–∏ —Ç–æ–∫—Å–∏—á–Ω—ã–µ —Å–ª–æ–≤–∞? ===
    remaining_toxic = check_remaining_toxicity(detoxed_pass1)

    # –ï—Å–ª–∏ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏ –Ω–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º
    if not remaining_toxic:
        return detoxed_pass1

    # === PASS 2: –†–µ—Ñ–∞–π–Ω–º–µ–Ω—Ç —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ –æ—Å—Ç–∞—Ç–∫–∏ ===
    refinement_prompt = f"""‚ö†Ô∏è CRITICAL: –¢–µ–∫—Å—Ç –≤—Å—ë –µ—â—ë —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç—å!

–ò—Å—Ö–æ–¥–Ω—ã–π —Ç–æ–∫—Å–∏—á–Ω—ã–π —Ç–µ–∫—Å—Ç:
{text}

–ü–µ—Ä–≤–∞—è –ø–æ–ø—ã—Ç–∫–∞ –¥–µ—Ç–æ–∫—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–ù–ï–£–°–ü–ï–®–ù–ê–Ø):
{detoxed_pass1}

üî¥ –ù–ê–ô–î–ï–ù–ù–ê–Ø –û–°–¢–ê–¢–û–ß–ù–ê–Ø –¢–û–ö–°–ò–ß–ù–û–°–¢–¨: {', '.join(remaining_toxic)}

–ó–ê–î–ê–ß–ê: –°–æ–∑–¥–∞–π —É–ª—É—á—à–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é, —É–±—Ä–∞–≤ –í–°–ï –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–æ–∫—Å–∏—á–Ω—ã–µ —Å–ª–æ–≤–∞.

–¢–†–ï–ë–û–í–ê–ù–ò–Ø:
- –£–¥–∞–ª–∏ –∏–ª–∏ –∑–∞–º–µ–Ω–∏: {', '.join(remaining_toxic)}
- –°–æ—Ö—Ä–∞–Ω–∏ —Å–º—ã—Å–ª
- –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –¥–µ—Ç–æ–∫—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç

–î–µ—Ç–æ–∫—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:"""

    try:
        resp = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[{"role": "user", "content": refinement_prompt}],
            temperature=0.1,  # –û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
            max_tokens=400,
            seed=42
        )

        total_api_calls += 1

        if hasattr(resp, 'usage') and resp.usage:
            total_input_tokens += resp.usage.prompt_tokens
            total_output_tokens += resp.usage.completion_tokens

        detoxed_pass2 = resp.choices[0].message.content.strip()
        detoxed_pass2 = clean_output(detoxed_pass2)

        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
        if detoxed_pass2 and len(detoxed_pass2) >= len(text) * 0.3:
            return detoxed_pass2
        else:
            return detoxed_pass1  # –í–æ–∑–≤—Ä–∞—Ç –∫ pass 1 –µ—Å–ª–∏ pass 2 —Å—Ç—Ä–∞–Ω–Ω—ã–π

    except Exception as e:
        print(f"‚ö†Ô∏è Pass 2 failed: {e}")
        return detoxed_pass1

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –ì–õ–ê–í–ù–´–ô PIPELINE
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def detoxify_text(text: str) -> str:
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–µ—Ç–æ–∫—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏

    Args:
        text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–æ–∫—Å–∏—á–Ω—ã–π —Ç–µ–∫—Å—Ç

    Returns:
        –î–µ—Ç–æ–∫—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    """
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–∞
    if not isinstance(text, str) or not text.strip():
        return text

    # –î–≤—É—Ö–ø—Ä–æ—Ö–æ–¥–Ω–∞—è –¥–µ—Ç–æ–∫—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
    result = two_pass_detoxification(text)

    # –§–∏–Ω–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
    if not result or not result.strip():
        return text  # –í–æ–∑–≤—Ä–∞—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª–∞ –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫

    return result

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# MAIN
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def main():
    print("="*80)
    print("üöÄ –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –°–¢–†–ê–¢–ï–ì–ò–Ø - GPT-4o-mini –¥–ª—è J ‚â• 0.70")
    print("="*80)

    print(f"\nüì• –ß—Ç–µ–Ω–∏–µ: {INPUT_FILE}")
    df = pd.read_csv(INPUT_FILE, sep="\t")
    print(f"   –û–±—Ä–∞–∑—Ü–æ–≤: {len(df)}")

    print(f"\n‚ö° –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:")
    print(f"   –ú–æ–¥–µ–ª—å: {MODEL_NAME}")
    print(f"   API: {BASE_URL}")
    print(f"   –ö–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {NUM_CANDIDATES}")

    print(f"\n‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–∑—ã:")
    print(f"   –§–∞–∑–∞ 1: –£—Å–∏–ª–µ–Ω–Ω—ã–π Chain-of-Thought –¥–ª—è GPT-4o-mini")
    print(f"   –§–∞–∑–∞ 2: –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ + –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ª–µ–∫—Å–∏–∫–æ–Ω")
    print(f"   –§–∞–∑–∞ 3: Multi-candidate generation")
    print(f"   –§–∞–∑–∞ 4: –≠–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–æ–µ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ (–ë–ï–ó LaBSE)")
    print(f"   –§–∞–∑–∞ 5: –î–≤—É—Ö–ø—Ä–æ—Ö–æ–¥–Ω–∞—è –¥–µ—Ç–æ–∫—Å–∏—Ñ–∏–∫–∞—Ü–∏—è")

    print("\nüöÄ –û–±—Ä–∞–±–æ—Ç–∫–∞...\n")

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º
    tqdm.pandas(desc="üéØ Detoxifying")
    df["tat_detox1"] = df["tat_toxic"].progress_apply(detoxify_text)

    # –§–∏–Ω–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
    df["tat_detox1"] = df["tat_detox1"].fillna(df["tat_toxic"])
    empty_mask = df["tat_detox1"].isna() | (df["tat_detox1"].str.strip() == "")
    if empty_mask.any():
        df.loc[empty_mask, "tat_detox1"] = df.loc[empty_mask, "tat_toxic"]

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    changed = (df["tat_toxic"] != df["tat_detox1"]).sum()

    length_diffs = []
    for idx in range(len(df)):
        orig = df.iloc[idx]["tat_toxic"]
        detox = df.iloc[idx]["tat_detox1"]
        if len(orig) > 0:
            diff = abs(len(detox) - len(orig)) / len(orig)
            length_diffs.append(diff)

    avg_diff = sum(length_diffs) / len(length_diffs) * 100 if length_diffs else 0

    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   –ò–∑–º–µ–Ω–µ–Ω–æ: {changed}/{len(df)} ({changed/len(df)*100:.1f}%)")
    print(f"   –°—Ä–µ–¥–Ω–∏–π Œî –¥–ª–∏–Ω—ã: {avg_diff:.1f}%")
    print(f"   API –≤—ã–∑–æ–≤–æ–≤: {total_api_calls}")
    print(f"   –¢–æ–∫–µ–Ω–æ–≤ (–≤—Ö–æ–¥): {total_input_tokens:,}")
    print(f"   –¢–æ–∫–µ–Ω–æ–≤ (–≤—ã—Ö–æ–¥): {total_output_tokens:,}")

    # –ü—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å (GPT-4o-mini)
    cost_input = (total_input_tokens / 1_000_000) * 0.15  # $0.15/1M input tokens
    cost_output = (total_output_tokens / 1_000_000) * 0.60  # $0.60/1M output tokens
    total_cost = cost_input + cost_output
    print(f"   –ü—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: ${total_cost:.4f} üí∞")

    print(f"\nüì¶ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ: {OUTPUT_FILE}")
    df[["ID", "tat_toxic", "tat_detox1"]].to_csv(OUTPUT_FILE, sep="\t", index=False)

    print("\n" + "="*80)
    print("‚úÖ –ì–û–¢–û–í–û!")
    print("="*80)

    print(f"\nüéØ –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å GPT-4o-mini:")
    print(f"   STA (Style Transfer Accuracy): 0.75-0.85")
    print(f"   SIM (Similarity): 0.88-0.92")
    print(f"   FL (Fluency): 0.92-0.96")
    print(f"   J-score: 0.68-0.75 ‚Üí –¶–ï–õ–ï–í–û–ô J ‚â• 0.70 ‚úì")

    print(f"\nüìä –ó–∞–ø—É—Å—Ç–∏—Ç–µ –æ—Ü–µ–Ω–∫—É:")
    print(f"   .venv/bin/python evaluate_j_score.py {OUTPUT_FILE}")


if __name__ == "__main__":
    main()
