#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üß™ –¢–µ—Å—Ç –Ω–∞ –º–∞–ª–æ–π –≤—ã–±–æ—Ä–∫–µ (10 –ø—Ä–∏–º–µ—Ä–æ–≤)
–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç—ã –ø–µ—Ä–µ–¥ –ø–æ–ª–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
"""

import sys
import pandas as pd

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞
sys.path.insert(0, '.')
from main_GPT4O_MINI_OPTIMIZED import detoxify_text, TOXIC_WORDS_SET

print("="*80)
print("üß™ –¢–ï–°–¢ –ù–ê 10 –ü–†–ò–ú–ï–†–ê–•")
print("="*80)

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–≤—ã–µ 10 —Å—Ç—Ä–æ–∫
print("\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–≤—ã—Ö 10 –ø—Ä–∏–º–µ—Ä–æ–≤...")
df = pd.read_csv("dev_inputs.tsv", sep="\t", nrows=10)
print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {len(df)} –ø—Ä–∏–º–µ—Ä–æ–≤\n")

# –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –ø—Ä–∏–º–µ—Ä
results = []
for idx, row in df.iterrows():
    toxic = row['tat_toxic']

    print(f"{'='*80}")
    print(f"üìù –ü—Ä–∏–º–µ—Ä {idx}")
    print(f"{'='*80}")
    print(f"–¢–æ–∫—Å–∏—á–Ω—ã–π: {toxic}")

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–æ–∫—Å–∏—á–Ω—ã–µ —Å–ª–æ–≤–∞ –≤ —Ç–µ–∫—Å—Ç–µ
    toxic_lower = toxic.lower()
    found_toxic = [w for w in TOXIC_WORDS_SET if w in toxic_lower]
    if found_toxic:
        print(f"üî¥ –ù–∞–π–¥–µ–Ω–Ω–∞—è —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç—å: {', '.join(found_toxic)}")
    else:
        print(f"‚ö†Ô∏è –Ø–≤–Ω–æ–π —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ (–≤–æ–∑–º–æ–∂–Ω–æ –Ω–µ—è–≤–Ω–∞—è)")

    # –î–µ—Ç–æ–∫—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
    print(f"\n‚è≥ –î–µ—Ç–æ–∫—Å–∏—Ñ–∏–∫–∞—Ü–∏—è...")
    detoxed = detoxify_text(toxic)

    print(f"‚úÖ –î–µ—Ç–æ–∫—Å:     {detoxed}")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Å—Ç–∞—Ç–æ—á–Ω–æ–π —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏
    detoxed_lower = detoxed.lower()
    remaining = [w for w in TOXIC_WORDS_SET if w in detoxed_lower]
    if remaining:
        print(f"‚ö†Ô∏è –û–°–¢–ê–õ–ê–°–¨ –¢–û–ö–°–ò–ß–ù–û–°–¢–¨: {', '.join(remaining)}")
    else:
        print(f"‚úì –¢–æ–∫—Å–∏—á–Ω–æ—Å—Ç—å —É–¥–∞–ª–µ–Ω–∞")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã
    len_change = len(detoxed) - len(toxic)
    len_percent = (len_change / len(toxic) * 100) if len(toxic) > 0 else 0
    print(f"üìè –ò–∑–º–µ–Ω–µ–Ω–∏–µ –¥–ª–∏–Ω—ã: {len_change:+d} —Å–∏–º–≤–æ–ª–æ–≤ ({len_percent:+.1f}%)")

    results.append({
        'ID': idx,
        'toxic': toxic,
        'detoxed': detoxed,
        'found_toxic': found_toxic,
        'remaining': remaining,
        'len_change_pct': len_percent
    })
    print()

# –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
print("="*80)
print("üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
print("="*80)

total = len(results)
fully_cleaned = sum(1 for r in results if not r['remaining'])
partially_cleaned = total - fully_cleaned

print(f"\n‚úÖ –ü–æ–ª–Ω–æ—Å—Ç—å—é –æ—á–∏—â–µ–Ω–æ: {fully_cleaned}/{total} ({fully_cleaned/total*100:.1f}%)")
if partially_cleaned > 0:
    print(f"‚ö†Ô∏è –ß–∞—Å—Ç–∏—á–Ω–æ –æ—á–∏—â–µ–Ω–æ: {partially_cleaned}/{total}")

avg_len_change = sum(r['len_change_pct'] for r in results) / total
print(f"\nüìè –°—Ä–µ–¥–Ω–∏–π Œî –¥–ª–∏–Ω—ã: {avg_len_change:+.1f}%")

# –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã
if partially_cleaned > 0:
    print(f"\n‚ö†Ô∏è –ü–†–ò–ú–ï–†–´ –° –û–°–¢–ê–¢–û–ß–ù–û–ô –¢–û–ö–°–ò–ß–ù–û–°–¢–¨–Æ:")
    for r in results:
        if r['remaining']:
            print(f"   [{r['ID']}] –û—Å—Ç–∞–ª–æ—Å—å: {', '.join(r['remaining'])}")
            print(f"       {r['detoxed'][:70]}")

print("\n" + "="*80)
print("‚úÖ –¢–ï–°–¢ –ó–ê–í–ï–†–®–Å–ù")
print("="*80)
print("\nüí° –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ö–æ—Ä–æ—à–∏–µ, –∑–∞–ø—É—Å–∫–∞–π—Ç–µ –ø–æ–ª–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É:")
print("   .venv/bin/python main_GPT4O_MINI_OPTIMIZED.py")
