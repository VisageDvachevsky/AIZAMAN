#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ¯ FINAL OPTIMIZED SOLUTION for Tatar Text Detoxification
Issue #3: Optimize for J-score â‰¥ 0.70

Key improvements:
1. PARALLEL API calls (5-10 concurrent) to meet 30-minute time limit
2. OPTIMIZED prompt (~1000 tokens instead of ~1500-2000)
3. BETTER disguised profanity detection (Ğ—Ğ°Ğ¸Ğ¿Ğ°Ğ»Ğ¸, etc.)
4. MORPHOLOGICAL variant handling (ĞºÑƒÑ‚/ĞºÑƒÑ‚ĞµĞ½Ñ/ĞºÑƒÑ‚ĞµĞ½)
5. PRESERVE @user mentions to maintain SIM score
6. Two-pass detoxification for problematic texts

Target metrics:
- STA (detoxification): â‰¥0.88
- SIM (similarity): â‰¥0.94
- FL (fluency): â‰¥0.94
- J-score: â‰¥0.70

Time constraint: â‰¤30 minutes for 600 examples
Speed target: <3 seconds per example

Author: AI Issue Solver
Date: 2025-11-30
"""

import re
import os
import pandas as pd
from openai import OpenAI
from tqdm import tqdm
import time
from functools import lru_cache
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# API CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

API_KEY = "sk-C4Ju9Yy2-EKOf6SHs-jBPA"
BASE_URL = "https://api.artemox.com/v1"
MODEL_NAME = "gpt-4o-mini"

client = OpenAI(
    api_key=API_KEY,
    base_url=BASE_URL
)

# Settings
INPUT_FILE = "dev_inputs.tsv"
OUTPUT_FILE = "submission_final.tsv"
MAX_RETRIES = 3
RETRY_DELAY = 1
MAX_WORKERS = 8  # Parallel API calls

# Counters (thread-safe)
counter_lock = threading.Lock()
total_api_calls = 0
total_input_tokens = 0
total_output_tokens = 0

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EXPANDED TOXIC LEXICON WITH MORPHOLOGICAL VARIANTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

TOXIC_PATTERNS = {
    # === DISGUISED PROFANITY (CRITICAL - often missed) ===
    'disguised': [
        ('Ğ·Ğ°Ğ¸Ğ¿Ğ°Ğ»', r'Ğ·Ğ°Ğ¸Ğ¿Ğ°Ğ»[Ğ¸Ğ¾Ğ°]'),        # Ğ·Ğ°ĞµĞ±Ğ°Ğ»Ğ¸ disguised
        ('Ğ½Ğ°Ñ…ÑƒĞ¹', r'Ğ½Ğ°Ñ…[ÑƒĞµ]Ğ¹'),            # Ğ½Ğ°Ñ…ÑƒĞ¹
        ('Ğ¿Ğ¾Ñ…ÑƒĞ¹', r'Ğ¿Ğ¾Ñ…[ÑƒĞµ]Ğ¹'),            # Ğ¿Ğ¾Ñ…ÑƒĞ¹
        ('Ğ±Ğ»ÑÑÑ', r'Ğ±Ğ»Ñ{2,}'),             # extended Ğ±Ğ»Ñ
        ('Ñ…ÑƒĞ¹Ğ¹', r'Ñ…Ñƒ+Ğ¹+'),                # extended Ñ…ÑƒĞ¹
    ],

    # === RUSSIAN STRONG PROFANITY ===
    'russian_strong': [
        ('Ğ±Ğ»Ñ', r'\bĞ±Ğ»Ñ[Ñ‚Ğ´ÑŒ]?\b'),
        ('Ñ…ÑƒĞ¹', r'\bÑ…Ñƒ[Ğ¹Ñ‘ĞµÑ]\b'),
        ('Ñ…ÑƒĞ¹Ğ½Ñ', r'Ñ…ÑƒĞ¹Ğ½[ÑÑƒĞµ]'),
        ('Ğ¿Ğ¸Ğ·Ğ´', r'Ğ¿Ğ¸Ğ·Ğ´[Ğ°ĞµÑƒĞ¾Ğ¹]?'),
        ('ĞµĞ±Ğ°Ğ½', r'[ĞµÑ‘]Ğ±Ğ°Ğ½[Ğ°Ñ‹Ğ¾Ğµ]?'),
        ('ĞµĞ±Ğ°Ñ‚ÑŒ', r'[ĞµÑ‘]Ğ±Ğ°[Ñ‚Ğ»][ÑŒĞ¸]?'),
        ('ÑÑƒĞºĞ°', r'\bÑÑƒĞº[Ğ°Ğ¸]\b'),
        ('Ğ¿Ğ¸Ğ´Ğ¾Ñ€', r'Ğ¿Ğ¸Ğ´Ğ¾Ñ€|Ğ¿Ğ¸Ğ´Ğ°Ñ€'),
        ('Ğ±Ğ»ÑÑ‚', r'Ğ±Ğ»ÑÑ‚[ÑŒĞ¸]?'),
    ],

    # === RUSSIAN VULGAR ===
    'russian_vulgar': [
        ('Ğ¶Ğ¾Ğ¿', r'Ğ¶Ğ¾Ğ¿[Ğ°ĞµÑƒĞ¾Ğ¹Ñ‹]?'),
        ('ÑÑ€Ğ°Ñ‚ÑŒ', r'ÑÑ€Ğ°[Ñ‚Ğ»Ğ½]|ÑÑ€Ñƒ'),
        ('Ğ³Ğ¾Ğ²Ğ½Ğ¾', r'Ğ³Ğ¾Ğ²Ğ½[Ğ¾Ğ°ÑƒĞµ]'),
        ('Ğ´ĞµÑ€ÑŒĞ¼Ğ¾', r'Ğ´ĞµÑ€ÑŒĞ¼[Ğ¾Ğ°Ñƒ]'),
    ],

    # === RUSSIAN MILD (less aggressive removal) ===
    'russian_mild': [
        ('Ğ±Ğ»Ğ¸Ğ½', r'\bĞ±Ğ»Ğ¸Ğ½\b'),
        ('Ñ…Ñ€ĞµĞ½', r'\bÑ…Ñ€ĞµĞ½[Ğ°Ğ¾ÑƒÑ‹]?\b'),
        ('Ñ‡ĞµÑ€Ñ‚', r'\bÑ‡ĞµÑ€Ñ‚[Ğ°Ğ¾Ñƒ]?\b'),
    ],

    # === TATAR OFFENSIVE (ALL MORPHOLOGICAL VARIANTS) ===
    'tatar_offensive': [
        ('ĞºÑƒÑ‚Ğ°Ğº', r'ĞºÑƒÑ‚Ğ°[ĞºĞºĞ³]'),           # ĞºÑƒÑ‚Ğ°Ğº = ass
        ('ĞºÑƒÑ‚', r'\bĞºÑƒÑ‚[ĞµĞ½Ğµ]?\b'),         # ĞºÑƒÑ‚ = ass (root)
        ('ĞºÑƒÑ‚ĞµĞ½', r'ĞºÑƒÑ‚ĞµĞ½[ÑĞµĞ°]'),          # ĞºÑƒÑ‚ĞµĞ½Ğµ, ĞºÑƒÑ‚ĞµĞ½Ğ°
        ('Ñ‡ÑƒÑ‡ĞºĞ°', r'Ñ‡ÑƒÑ‡Ğº[Ğ°ÑƒĞ¾ĞµĞ¸]'),         # ÑĞ²Ğ¸Ğ½ÑŒÑ
        ('Ğ´ÑƒĞ½Ğ³Ñ‹Ğ·', r'Ğ´ÑƒĞ½Ğ³Ñ‹Ğ·'),             # ÑĞ²Ğ¸Ğ½ÑŒÑ
        ('Ñ‚Ğ¸Ğ»Ğµ', r'\bÑ‚Ğ¸Ğ»Ğµ\b'),             # ÑÑƒĞ¼Ğ°ÑÑˆĞµĞ´ÑˆĞ¸Ğ¹
        ('Ğ°Ğ½Ğ³Ñ‹Ñ€Ğ°', r'Ğ°Ğ½Ğ³Ñ‹Ñ€[Ğ°ÑƒÑ‹]'),         # Ğ¸Ğ´Ğ¸Ğ¾Ñ‚
        ('ÑĞ¾ÑĞ¾Ğ¿', r'ÑĞ¾ÑĞ¾Ğ¿'),               # ÑĞ¾ÑĞ°Ñ‚ÑŒ (vulgar)
        ('Ñ‚Ğ¸Ğ½Ñ‚ÑĞº', r'Ñ‚Ğ¸Ğ½Ñ‚[ÑĞµ]Ğº'),          # fool
        ('ĞºÑƒÑ‚Ğ»Ğ°Ğº', r'ĞºÑƒÑ‚Ğ»Ğ°[ĞºĞºĞ³]'),         # ass-related
        ('ĞºÑƒÑ‚Ñ‚Ğ°Ğº', r'ĞºÑƒÑ‚Ñ‚Ğ°[ĞºĞºĞ³]'),         # ass-related variant
    ],

    # === CODE-SWITCHING CONSTRUCTIONS ===
    'code_switching': [
        ('Ğ½Ğ° Ñ…ÑƒĞ¹', r'Ğ½Ğ°\s*Ñ…[ÑƒĞµ][Ğ¹Ñ€]'),
        ('Ğ¿Ğ¾ÑˆĞ¾Ğ»', r'Ğ¿Ğ¾ÑˆĞ¾Ğ»\s*Ğ½Ğ°'),
        ('Ğ¸Ğ´Ğ¸ Ğ½Ğ°', r'Ğ¸Ğ´Ğ¸\s*Ğ½Ğ°\s*Ñ…'),
        ('Ğ´Ğ¾Ñ…ÑƒÑ', r'Ğ´Ğ¾Ñ…[ÑƒĞµ][Ğ¹Ñ]'),
    ],

    # === OFFENSIVE RUSSIAN WORDS ===
    'offensive': [
        ('ÑĞ²Ğ¾Ğ»Ğ¾Ñ‡ÑŒ', r'ÑĞ²Ğ¾Ğ»Ğ¾Ñ‡[ÑŒĞ¸]'),
        ('Ğ¸Ğ´Ğ¸Ğ¾Ñ‚', r'Ğ¸Ğ´Ğ¸Ğ¾Ñ‚'),
        ('Ğ´ĞµĞ±Ğ¸Ğ»', r'Ğ´ĞµĞ±Ğ¸Ğ»'),
        ('ÑƒÑ€Ğ¾Ğ´', r'ÑƒÑ€Ğ¾Ğ´'),
        ('Ñ‚Ğ²Ğ°Ñ€ÑŒ', r'Ñ‚Ğ²Ğ°Ñ€[ÑŒĞ¸]'),
        ('ĞºĞ¾Ğ·ĞµĞ»', r'ĞºĞ¾Ğ·ĞµĞ»|ĞºĞ¾Ğ·Ñ‘Ğ»'),
        ('Ğ¼ÑƒĞ´Ğ°Ğº', r'Ğ¼ÑƒĞ´Ğ°Ğº'),
        ('Ğ¿Ñ€Ğ¸Ğ´ÑƒÑ€Ğ¾Ğº', r'Ğ¿Ñ€Ğ¸Ğ´ÑƒÑ€[Ğ¾Ğ°]Ğº'),
        ('Ñ‚ÑƒĞ¿Ğ¾Ğ¹', r'Ñ‚ÑƒĞ¿Ğ¾[Ğ¹Ğµ]'),
        ('Ğ´ÑƒÑ€Ğ°Ğº', r'Ğ´ÑƒÑ€Ğ°Ğº|Ğ´ÑƒÑ€Ğ°\b'),
    ],
}

def get_all_toxic_patterns():
    """Compile all toxic patterns for detection"""
    patterns = []
    for category, items in TOXIC_PATTERNS.items():
        for name, pattern in items:
            patterns.append((name, re.compile(pattern, re.IGNORECASE)))
    return patterns

COMPILED_PATTERNS = get_all_toxic_patterns()


def check_remaining_toxicity(text: str) -> list:
    """Check for remaining toxic patterns in text"""
    text_lower = text.lower()
    remaining = []
    for name, pattern in COMPILED_PATTERNS:
        if pattern.search(text_lower):
            remaining.append(name)
    return remaining


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# OPTIMIZED PROMPT (~1000 tokens instead of ~1500-2000)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def create_optimized_prompt(text: str) -> str:
    """
    Create optimized prompt (~1000 tokens) with focus on:
    1. Disguised profanity (Ğ—Ğ°Ğ¸Ğ¿Ğ°Ğ»Ğ¸)
    2. Morphological variants (ĞºÑƒÑ‚/ĞºÑƒÑ‚ĞµĞ½Ñ)
    3. Minimal changes (preserve SIM)
    4. Keep @user mentions
    """

    prompt = f"""Ğ”ĞµÑ‚Ğ¾ĞºÑĞ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€ÑƒĞ¹ Ñ‚Ğ°Ñ‚Ğ°Ñ€ÑĞºĞ¸Ğ¹ Ñ‚ĞµĞºÑÑ‚. Ğ£Ğ”ĞĞ›Ğ˜ Ñ‚Ğ¾ĞºÑĞ¸Ñ‡Ğ½ÑƒÑ Ğ»ĞµĞºÑĞ¸ĞºÑƒ, Ğ¡ĞĞ¥Ğ ĞĞĞ˜ ÑĞ¼Ñ‹ÑĞ».

âš ï¸ ĞĞ‘Ğ¯Ğ—ĞĞ¢Ğ•Ğ›Ğ¬ĞĞ Ğ£Ğ”ĞĞ›Ğ˜Ğ¢Ğ¬:
â€¢ Ğ ÑƒÑÑĞºĞ¸Ğµ Ğ¼Ğ°Ñ‚Ñ‹: Ğ±Ğ»Ñ, Ñ…ÑƒĞ¹, Ğ¿Ğ¸Ğ·Ğ´, ĞµĞ±Ğ°Ğ½, ÑÑƒĞºĞ°, Ğ¶Ğ¾Ğ¿Ğ°, ÑÑ€Ğ°Ñ‚ÑŒ, Ğ³Ğ¾Ğ²Ğ½Ğ¾
â€¢ Ğ—Ğ°Ğ¼Ğ°ÑĞºĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ: Ğ—Ğ°Ğ¸Ğ¿Ğ°Ğ»Ğ¸ (=Ğ·Ğ°ĞµĞ±Ğ°Ğ»Ğ¸), Ğ±Ğ»ÑÑÑ, Ğ½Ğ°Ñ…ÑƒĞ¹
â€¢ Ğ¢Ğ°Ñ‚Ğ°Ñ€ÑĞºĞ¸Ğµ: ĞºÑƒÑ‚Ğ°Ğº, ĞºÑƒÑ‚, ĞºÑƒÑ‚ĞµĞ½Ñ, Ñ‡ÑƒÑ‡ĞºĞ°, Ğ´ÑƒĞ½Ğ³Ñ‹Ğ·, Ñ‚Ğ¸Ğ»Ğµ, Ğ°Ğ½Ğ³Ñ‹Ñ€Ğ°, ÑĞ¾ÑĞ¾Ğ¿
â€¢ ĞÑĞºĞ¾Ñ€Ğ±Ğ»ĞµĞ½Ğ¸Ñ: ÑĞ²Ğ¾Ğ»Ğ¾Ñ‡ÑŒ, Ğ¸Ğ´Ğ¸Ğ¾Ñ‚, Ğ´ĞµĞ±Ğ¸Ğ», Ğ¿Ñ€Ğ¸Ğ´ÑƒÑ€Ğ¾Ğº, Ñ‚ÑƒĞ¿Ğ¾Ğ¹
â€¢ Ğ¡Ğ»Ğ°Ğ±Ñ‹Ğµ: Ğ±Ğ»Ğ¸Ğ½, Ñ…Ñ€ĞµĞ½ (ÑƒĞ´Ğ°Ğ»ÑÑ‚ÑŒ ĞµÑĞ»Ğ¸ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾)

âš ï¸ Ğ¡ĞĞ¥Ğ ĞĞĞ˜Ğ¢Ğ¬:
â€¢ @ÑƒĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ğ½Ğ¸Ñ (@user) - ĞĞ• Ñ‚Ğ¾ĞºÑĞ¸Ñ‡Ğ½Ñ‹
â€¢ Ğ¡Ğ¼Ñ‹ÑĞ», ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¸, ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ
â€¢ Ğ­Ğ¼Ğ¾Ğ´Ğ·Ğ¸, Ğ¿ÑƒĞ½ĞºÑ‚ÑƒĞ°Ñ†Ğ¸Ñ :) =D ))

ğŸ“‹ ĞŸĞ Ğ˜ĞœĞ•Ğ Ğ«:
Ğ¢Ğ¾ĞºÑ: ÑĞ¸Ğ½Ğµ Ğ°Ğ½Ğ´Ğ° ĞºĞ¾Ñ‚ĞµĞ¿ ÑÑ‚Ğ¼Ñ‹Ğ¹Ğ»Ğ°Ñ€, ÑĞ¸Ğ´Ğ¸ Ğ½Ğ° Ğ¶Ğ¾Ğ¿Ğµ
Ğ”ĞµÑ‚Ğ¾ĞºÑ: ÑĞ¸Ğ½Ğµ Ğ°Ğ½Ğ´Ğ° ĞºĞ¾Ñ‚ĞµĞ¿ ÑÑ‚Ğ¼Ñ‹Ğ¹Ğ»Ğ°Ñ€, ÑĞ¸Ğ´Ğ¸

Ğ¢Ğ¾ĞºÑ: Ğ—Ğ°Ğ¸Ğ¿Ğ°Ğ»Ğ¸, Ğ½ÑÑ€ÑÑ Ğ±ÑƒĞ»ÑĞº Ğ¸Ñ‚Ğ¸Ğ¼
Ğ”ĞµÑ‚Ğ¾ĞºÑ: ĞĞ°Ğ´Ğ¾ĞµĞ»Ğ¾, Ğ½ÑÑ€ÑÑ Ğ±ÑƒĞ»ÑĞº Ğ¸Ñ‚Ğ¸Ğ¼

Ğ¢Ğ¾ĞºÑ: @user, ÑĞ¸Ğ½ ĞºĞ¸Ğ» Ğ´Ğ°Ğ²Ğ°Ğ¹, ĞºÑƒÑ‚Ğ°Ğº ÑÑ‹Ñ€Ğ»Ğ°Ğ¼Ğ°!
Ğ”ĞµÑ‚Ğ¾ĞºÑ: @user, ÑĞ¸Ğ½ ĞºĞ¸Ğ» Ğ´Ğ°Ğ²Ğ°Ğ¹, ÑÑ‹Ñ€Ğ»Ğ°Ğ¼Ğ°!

Ğ¢Ğ¾ĞºÑ: Ğ£Ğ· ĞºÑƒÑ‚ĞµĞ½Ñ Ğ¿Ñ€Ğ¸ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ ÑĞ·Ğ»ÑĞ³ÑĞ½ÑĞµĞ½
Ğ”ĞµÑ‚Ğ¾ĞºÑ: Ğ£Ğ·Ğµ Ğ¿Ñ€Ğ¸ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ ÑĞ·Ğ»ÑĞ³ÑĞ½ÑĞµĞ½

Ğ¢Ğ¾ĞºÑ: ĞŸĞ°ÑˆĞ¾Ğ» Ğ½Ğ°Ñ…ÑƒĞ¹ ĞºÑƒÑ‚Ñ‚Ğ°ĞºĞ±Ğ°Ñˆ
Ğ”ĞµÑ‚Ğ¾ĞºÑ: Ğ‘Ğ°Ñ€ Ğ¸Ğ½Ğ´Ğµ

Ğ¢Ğ•ĞšĞ¡Ğ¢: {text}

Ğ”ĞµÑ‚Ğ¾ĞºÑ (Ğ¢ĞĞ›Ğ¬ĞšĞ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚):"""

    return prompt


def create_refinement_prompt(text: str, first_attempt: str, remaining: list) -> str:
    """Create focused refinement prompt for second pass"""
    return f"""âš ï¸ Ğ¢ĞĞšĞ¡Ğ˜Ğ§ĞĞĞ¡Ğ¢Ğ¬ ĞĞ¡Ğ¢ĞĞ›ĞĞ¡Ğ¬! Ğ˜ÑĞ¿Ñ€Ğ°Ğ²ÑŒ:

ĞÑ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»: {text}
ĞŸĞ¾Ğ¿Ñ‹Ñ‚ĞºĞ° 1: {first_attempt}
ĞÑÑ‚Ğ°Ğ»Ğ¾ÑÑŒ: {', '.join(remaining)}

Ğ£Ğ”ĞĞ›Ğ˜ ÑÑ‚Ğ¸ ÑĞ»Ğ¾Ğ²Ğ°, ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ğ¸ ÑĞ¼Ñ‹ÑĞ». Ğ’ĞµÑ€Ğ½Ğ¸ Ğ¢ĞĞ›Ğ¬ĞšĞ Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚:"""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PREPROCESSING - MINIMAL (preserve @user for SIM)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def preprocess(text: str) -> str:
    """
    MINIMAL preprocessing - do NOT remove @user
    This preserves similarity score
    """
    if not isinstance(text, str):
        return str(text) if text else ""

    # Only normalize whitespace
    result = re.sub(r'\s+', ' ', text).strip()

    return result if result else text


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# POSTPROCESSING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def postprocess(text: str, original: str) -> str:
    """
    Postprocess GPT output with validation
    """
    if not text:
        return original

    # Remove quotes
    text = text.strip('"\'`')

    # Remove GPT prefixes
    prefixes = [
        'Ğ´ĞµÑ‚Ğ¾ĞºÑ:', 'Ğ´ĞµÑ‚Ğ¾ĞºÑĞ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚:',
        'Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚:', 'Ğ¾Ñ‚Ğ²ĞµÑ‚:', 'output:',
        'Ğ´ĞµÑ‚Ğ¾ĞºÑĞ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹:', 'Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚:',
    ]
    text_lower = text.lower()
    for prefix in prefixes:
        if text_lower.startswith(prefix):
            text = text[len(prefix):].strip()
            break

    # If multiple lines, take first meaningful line
    lines = text.split('\n')
    clean_lines = []
    for line in lines:
        # Skip metadata lines
        if any(marker in line.lower() for marker in ['Ñ‚Ğ¾ĞºÑĞ¸Ñ‡Ğ½Ñ‹Ğ¹:', 'Ğ´ĞµÑ‚Ğ¾ĞºÑ:', 'ÑˆĞ°Ğ³ ', 'â”â”â”', 'Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»:', 'Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚ĞºĞ°']):
            continue
        if line.strip():
            clean_lines.append(line.strip())

    if clean_lines:
        text = clean_lines[0]

    # Validate length (not shorter than 20% of original)
    if len(text) < len(original) * 0.20:
        return original

    # Validate not empty
    if not text.strip():
        return original

    # Check for truncation (ends with preposition/conjunction)
    words = text.strip().split()
    if words and len(words) > 2:
        last_word = words[-1].lower().rstrip('.,!?;:')
        bad_endings = ['Ğ½Ğ°', 'Ğ²', 'Ñ', 'Ğº', 'Ğ¿Ğ¾', 'Ğ¾', 'Ğ·Ğ°', 'Ğ¾Ñ‚', 'Ñƒ', 'Ğ¸', 'Ğ°', 'Ğ½Ğ¾', 'Ğ´Ğ°', 'Ğ»Ğ¸', 'Ñ', 'Ñ']
        if last_word in bad_endings:
            # Truncation detected - return original
            return original

    return text


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN DETOXIFICATION FUNCTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def detoxify_single(text: str) -> str:
    """
    Detoxify a single text with two-pass approach if needed
    """
    global total_api_calls, total_input_tokens, total_output_tokens

    # Validate input
    if not isinstance(text, str) or not text.strip():
        return text if text else ""

    # Preprocess
    preprocessed = preprocess(text)

    # First pass
    prompt = create_optimized_prompt(preprocessed)

    for attempt in range(MAX_RETRIES):
        try:
            response = client.chat.completions.create(
                model=MODEL_NAME,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2,  # Lower for more deterministic output
                max_tokens=300,   # Reduced for speed
                top_p=0.9,
                seed=42
            )

            with counter_lock:
                total_api_calls += 1
                if hasattr(response, 'usage') and response.usage:
                    total_input_tokens += response.usage.prompt_tokens
                    total_output_tokens += response.usage.completion_tokens

            result = response.choices[0].message.content.strip()
            result = postprocess(result, text)

            # Check for remaining toxicity
            remaining = check_remaining_toxicity(result)

            if not remaining:
                return result

            # Second pass if toxicity remains
            refinement_prompt = create_refinement_prompt(text, result, remaining)

            response2 = client.chat.completions.create(
                model=MODEL_NAME,
                messages=[{"role": "user", "content": refinement_prompt}],
                temperature=0.1,  # Very low for accuracy
                max_tokens=300,
                seed=42
            )

            with counter_lock:
                total_api_calls += 1
                if hasattr(response2, 'usage') and response2.usage:
                    total_input_tokens += response2.usage.prompt_tokens
                    total_output_tokens += response2.usage.completion_tokens

            result2 = response2.choices[0].message.content.strip()
            result2 = postprocess(result2, text)

            # Return better result
            remaining2 = check_remaining_toxicity(result2)
            if len(remaining2) < len(remaining):
                return result2
            return result

        except Exception as e:
            if attempt < MAX_RETRIES - 1:
                time.sleep(RETRY_DELAY)
            else:
                print(f"âš ï¸ API error: {e}")
                return text

    return text


def detoxify_batch_parallel(texts: list, max_workers: int = MAX_WORKERS) -> list:
    """
    Detoxify texts in parallel using ThreadPoolExecutor
    """
    results = [None] * len(texts)

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # Submit all tasks
        future_to_idx = {
            executor.submit(detoxify_single, text): idx
            for idx, text in enumerate(texts)
        }

        # Process completed tasks with progress bar
        with tqdm(total=len(texts), desc="ğŸ¯ Ğ”ĞµÑ‚Ğ¾ĞºÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ") as pbar:
            for future in as_completed(future_to_idx):
                idx = future_to_idx[future]
                try:
                    results[idx] = future.result()
                except Exception as e:
                    print(f"âš ï¸ Error for idx {idx}: {e}")
                    results[idx] = texts[idx]  # Fallback to original
                pbar.update(1)

    return results


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    print("=" * 80)
    print("ğŸ¯ FINAL OPTIMIZED SOLUTION - Tatar Text Detoxification")
    print("   Issue #3: J-score â‰¥ 0.70 within 30 minutes")
    print("=" * 80)

    print(f"\nğŸ“¥ Reading: {INPUT_FILE}")
    df = pd.read_csv(INPUT_FILE, sep="\t")
    print(f"   Examples: {len(df)}")

    print(f"\nâš¡ Configuration:")
    print(f"   Model: {MODEL_NAME}")
    print(f"   API: {BASE_URL}")
    print(f"   Parallel workers: {MAX_WORKERS}")
    print(f"   Temperature: 0.2 (low for accuracy)")
    print(f"   Max tokens: 300 (optimized for speed)")

    print(f"\nâœ… Key improvements:")
    print(f"   â€¢ Parallel API calls ({MAX_WORKERS} workers)")
    print(f"   â€¢ Optimized prompt (~1000 tokens)")
    print(f"   â€¢ Disguised profanity handling (Ğ—Ğ°Ğ¸Ğ¿Ğ°Ğ»Ğ¸)")
    print(f"   â€¢ Morphological variants (ĞºÑƒÑ‚/ĞºÑƒÑ‚ĞµĞ½Ñ)")
    print(f"   â€¢ Preserve @user for SIM score")
    print(f"   â€¢ Two-pass detoxification when needed")

    print(f"\nğŸ¯ Target metrics:")
    print(f"   STA (detoxification): â‰¥0.88")
    print(f"   SIM (similarity): â‰¥0.94")
    print(f"   FL (fluency): â‰¥0.94")
    print(f"   J-score: â‰¥0.70")

    print(f"\nâ±ï¸ Time limit: 30 minutes")
    print(f"   Target speed: <3 sec/example")

    start_time = time.time()

    print("\nğŸš€ Processing...\n")

    # Get all texts
    texts = df["tat_toxic"].tolist()

    # Process in parallel
    results = detoxify_batch_parallel(texts, max_workers=MAX_WORKERS)

    # Assign results
    df["tat_detox1"] = results

    # Final validation
    df["tat_detox1"] = df["tat_detox1"].fillna(df["tat_toxic"])
    empty_mask = df["tat_detox1"].isna() | (df["tat_detox1"].str.strip() == "")
    if empty_mask.any():
        print(f"   Fixing empty: {empty_mask.sum()}")
        df.loc[empty_mask, "tat_detox1"] = df.loc[empty_mask, "tat_toxic"]

    end_time = time.time()
    elapsed = end_time - start_time

    # Statistics
    changed = (df["tat_toxic"] != df["tat_detox1"]).sum()

    length_diffs = []
    for idx in range(len(df)):
        orig = df.iloc[idx]["tat_toxic"]
        detox = df.iloc[idx]["tat_detox1"]
        if len(orig) > 0:
            diff = abs(len(detox) - len(orig)) / len(orig)
            length_diffs.append(diff)

    avg_diff = sum(length_diffs) / len(length_diffs) * 100 if length_diffs else 0

    # Check remaining toxicity
    remaining_toxic_count = 0
    for idx in range(len(df)):
        detox = df.iloc[idx]["tat_detox1"]
        if check_remaining_toxicity(detox):
            remaining_toxic_count += 1

    print(f"\nğŸ“Š Statistics:")
    print(f"   Total: {len(df)}")
    print(f"   Changed: {changed} ({changed/len(df)*100:.1f}%)")
    print(f"   Mean Î” length: {avg_diff:.1f}%")
    print(f"   Remaining toxic: {remaining_toxic_count}")
    print(f"   API calls: {total_api_calls}")
    print(f"   Tokens (input): {total_input_tokens:,}")
    print(f"   Tokens (output): {total_output_tokens:,}")
    print(f"   Time elapsed: {elapsed:.1f} seconds ({elapsed/60:.1f} minutes)")
    print(f"   Speed: {elapsed/len(df):.2f} sec/example")

    # Cost (GPT-4o-mini)
    cost_input = (total_input_tokens / 1_000_000) * 0.15
    cost_output = (total_output_tokens / 1_000_000) * 0.60
    total_cost = cost_input + cost_output
    print(f"   Estimated cost: ${total_cost:.4f}")

    print(f"\nğŸ“¦ Saving: {OUTPUT_FILE}")
    df[["ID", "tat_toxic", "tat_detox1"]].to_csv(OUTPUT_FILE, sep="\t", index=False)

    print("\n" + "=" * 80)
    print("âœ… DONE!")
    print("=" * 80)

    # Show examples
    print("\nğŸ“‹ Example changes (first 10):\n")
    shown = 0
    for idx in range(len(df)):
        orig = df.iloc[idx]["tat_toxic"]
        detox = df.iloc[idx]["tat_detox1"]

        if orig != detox and shown < 10:
            diff_pct = abs(len(detox) - len(orig)) / len(orig) * 100 if len(orig) > 0 else 0
            remaining = check_remaining_toxicity(detox)
            status = "âš ï¸" if remaining else "âœ…"
            print(f"[{idx}] Î”{diff_pct:.0f}% {status}")
            print(f"ğŸ”´ {orig[:70]}{'...' if len(orig) > 70 else ''}")
            print(f"ğŸŸ¢ {detox[:70]}{'...' if len(detox) > 70 else ''}")
            if remaining:
                print(f"   Remaining: {', '.join(remaining)}")
            print()
            shown += 1

    print(f"\nğŸ“Š Run evaluation:")
    print(f"   python evaluate_j_score.py {OUTPUT_FILE}")

    if elapsed > 1800:  # 30 minutes
        print(f"\nâš ï¸ WARNING: Processing took {elapsed/60:.1f} minutes (>30 min limit)")
        print(f"   Consider increasing MAX_WORKERS or reducing NUM_RETRIES")
    else:
        print(f"\nâœ… Time constraint met: {elapsed/60:.1f} minutes (<30 min)")


if __name__ == "__main__":
    main()
